---
title: "Collaborative Research in the Open"
subtitle: "Building scientific tools alongside the communities that use them"
date: 2024-06-10
image: "/images/posts/post-9.png"
author: "Paqari Team"
categories:
  - scientific
featured: false
---
Working with scientists and citizen researchers means embracing transparency. Every project starts with an open canvas where we document hypotheses, equipment needs, and ethical considerations. That shared plan guides the hardware design and software pipelines we develop at Paqari Open Lab.

## Open research charter

Our charter acts as the backbone for every collaboration. It outlines roles, contribution guidelines, and how we handle data stewardship. Partners sign it before building to ensure expectations are clear.

![Researchers co-designing an open science protocol](/images/posts/post-9.png)

### Charter highlights

- **Shared glossary:** Aligns scientific terms, translations, and local references.
- **Ethics checklist:** Confirms consent flows, anonymization routines, and open licensing.
- **Iteration cadence:** Establishes weekly syncs plus asynchronous review windows.

> **Reminder:** If a study does not need a particular safeguard, leave that section blank and the published guide will skip it automatically.

## Field kit assembly

We co-create modular field kits so teams can collect data in diverse environments. Each kit includes labeled containers, calibration cards, and QR codes that link to setup videos.

![Open hardware kit with sensors and calibration cards](/images/posts/post-2.png)

### Deployment workflow

1. **Assemble:** Print the packing list and confirm every component is tagged for tracking.
2. **Calibrate:** Run the `SensorCheck` script while comparing with the baseline dataset.
3. **Document:** Capture photos of the setup and log environmental conditions in the shared repository.
4. **Sync:** Upload data packets nightly; the pipeline validates schemas and flags anomalies.

## Community lab sessions

We host open sessions to review the instrumentation, calibrate sensors, and validate data flows. Participants can fork our documentation, test new configurations, and suggest improvements. The process ensures that the final tool remains adaptable and accountable to the people collecting the data.

| Session type | Focus | Recommended duration |
| --- | --- | --- |
| Hardware clinic | Inspect wear, replace consumables, and update firmware | 90 minutes |
| Data dive | Explore datasets, clean outliers, co-write insights | 2 hours |
| Replication sprint | Rebuild the experiment with new participants | Half day |

Publishing the results is just the beginning. We encourage teams to keep iterating, publish their learnings, and invite others to replicate the experiments. Collaboration keeps the scientific method alive and accessible.
